{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "##Loading the data \n",
    "raw_data = np.loadtxt('Audiobooks_data.csv', delimiter=',')\n",
    "\n",
    "raw_inputs = raw_data[:, 1:-1]\n",
    "raw_targets = raw_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I will use mulitple techniques for preprocessing in order to check which yields the best results\n",
    "## I will vary shuffling and scaling the features and balancing \n",
    "## Manual Balancing, Shuffling Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Balancing\n",
    "import numpy as np \n",
    " \n",
    "num_ones = int(np.sum(raw_targets))\n",
    "zeros = 0\n",
    "to_remove = []\n",
    "\n",
    "\n",
    "for i in range(raw_targets.shape[0]):\n",
    "    if raw_targets[i] == 0:\n",
    "        zeros += 1\n",
    "        if zeros > num_ones:\n",
    "            to_remove.append(i)\n",
    "\n",
    "\n",
    "manual_bal_ins = np.delete(raw_inputs, to_remove, axis=0)\n",
    "manual_bal_outs = np.delete(raw_targets, to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Scale\n",
    "manual_bal_ins = preprocessing.scale(manual_bal_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Shuffling \n",
    "shuffled = np.arange(manual_bal_ins.shape[0])\n",
    "np.random.shuffle(shuffled)\n",
    "\n",
    "man_Bal_Shuffle_ins = manual_bal_ins[shuffled]\n",
    "man_Bal_Shuffle_outs = manual_bal_outs[shuffled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual Splitting \n",
    "sampled = man_Bal_Shuffle_ins.shape[0]\n",
    "\n",
    "\n",
    "# Naturally, the numbers are integers.\n",
    "train_count = int(0.8 * sampled)\n",
    "validation_count = int(0.1 * sampled)\n",
    "test_count = sampled - train_count - validation_count\n",
    "\n",
    "\n",
    "man_ins_train = man_Bal_Shuffle_ins[:train_count]\n",
    "man_outs_train = man_Bal_Shuffle_outs[:train_count]\n",
    "\n",
    "man_ins_validation = man_Bal_Shuffle_ins[train_count:train_count+validation_count]\n",
    "man_outs_validation = man_Bal_Shuffle_outs[train_count:train_count+validation_count]\n",
    "\n",
    "man_ins_test = man_Bal_Shuffle_ins[train_count+validation_count:]\n",
    "man_outs_test = man_Bal_Shuffle_outs[train_count+validation_count:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sets\n",
    "## Status: Balanced, Scaled, Shuffled, Split \n",
    "## Usage: Manual\n",
    "\"\"\"\n",
    "man_ins_test, \n",
    "man_ins_train, \n",
    "man_ins_validation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Balancing through Imbalanced Learn \n",
    "## Naive Under Sampling \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "Under_sampler = RandomUnderSampler(random_state=69, replacement=False)\n",
    "x_underSampled, y_underSampled = Under_sampler.fit_resample(raw_inputs, raw_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Random Over sampling using Syntethics \n",
    "from imblearn.over_sampling import SMOTE \n",
    "Synth_Over_Sampler = SMOTE()\n",
    "x_OverSampled, y_OverSampled = Synth_Over_Sampler.fit_resample(raw_inputs, raw_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Under sampling using Distance Metrics \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "Tomekker = TomekLinks()\n",
    "x_UnderSampled_Dis, y_UnderSampled_Dis = Tomekker.fit_resample(raw_inputs, raw_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the data \n",
    "from sklearn import preprocessing\n",
    "x_Scaled_OS = preprocessing.scale(x_OverSampled)\n",
    "x_Scaled_US = preprocessing.scale(x_underSampled)\n",
    "x_Scaled_Dis = preprocessing.scale(x_UnderSampled_Dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shuffling and splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_Scaled_Dis_train, x_Scaled_Dis_test, y_UnderSampled_Dis_train, y_UnderSampled_Dis_test = train_test_split(\n",
    "    x_Scaled_Dis, y_UnderSampled_Dis\n",
    ")\n",
    "x_Scaled_OS_train, x_Scaled_OS_test, y_UnderSampled_OS_train, y_UnderSampled_OS_test = train_test_split(\n",
    "    x_Scaled_OS, y_OverSampled\n",
    ")\n",
    "x_Scaled_US_train, x_Scaled_US_test, y_UnderSampled_US_train, y_UnderSampled_US_test = train_test_split(\n",
    "    x_Scaled_US, y_underSampled\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sets till now\n",
    "## Status: Balanced, Scaled, Split, Randomized.\n",
    "## Used: Imbalanced Learn for shuffling \n",
    "\"\"\"\n",
    "x,y_Scaled_Dis - train, test -> Under Sampled using Distance metric\n",
    "x,y_Scaled_OS - train, test -> Over Sampled using Random\n",
    "x,y_Scaled_US - train, test -> Under Sampled using Random\n",
    "\"\"\"\n",
    "## \n",
    "\"\"\"\n",
    "man_ins_test, \n",
    "man_ins_train, \n",
    "man_ins_validation\n",
    "\"\"\"\n",
    "## Status: Balanced, Scaled, Split, Randomized\n",
    "## Used: Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train a simple model and see the difference between manual and module methods\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple DNN with optional early stopping for manual set \n",
    "input_size = 10 \n",
    "output_size = 2\n",
    "\n",
    "layer_size = 50\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(layer_size, 'relu'),\n",
    "    tf.keras.layers.Dense(layer_size, 'relu'),\n",
    "    tf.keras.layers.Dense(output_size, 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Print the results of the evaluation of each set \n",
    "def fitting(x, x_test, y, y_test, _callbacks, val_data):\n",
    "   \n",
    "    model.fit(\n",
    "        x=x,\n",
    "        y=y, \n",
    "        batch_size=50,\n",
    "        epochs=50,\n",
    "        callbacks=_callbacks,\n",
    "        validation_data=val_data,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    results = model.evaluate(x=x_test, y=y_test)\n",
    "    \n",
    "\n",
    "\n",
    "    print('loss, acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 - 0s - loss: 0.3711 - accuracy: 0.7893 - val_loss: 0.3412 - val_accuracy: 0.7852 - 174ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "72/72 - 0s - loss: 0.3541 - accuracy: 0.7910 - val_loss: 0.4140 - val_accuracy: 0.7696 - 143ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "72/72 - 0s - loss: 0.3551 - accuracy: 0.7930 - val_loss: 0.4360 - val_accuracy: 0.7763 - 138ms/epoch - 2ms/step\n",
      "14/14 [==============================] - 0s 653us/step - loss: 0.3579 - accuracy: 0.8214\n",
      "loss, acc: [0.35787925124168396, 0.8214285969734192]\n"
     ]
    }
   ],
   "source": [
    "fitting(man_ins_train, \n",
    "        man_ins_test, \n",
    "        man_outs_train, \n",
    "        man_outs_test, early_stopping, [man_ins_validation, man_outs_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208/208 - 0s - loss: 0.2177 - accuracy: 0.9123 - 302ms/epoch - 1ms/step\n",
      "Epoch 2/50\n",
      "208/208 - 0s - loss: 0.2189 - accuracy: 0.9110 - 317ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "208/208 - 0s - loss: 0.2185 - accuracy: 0.9120 - 300ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "208/208 - 0s - loss: 0.2187 - accuracy: 0.9112 - 339ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "208/208 - 0s - loss: 0.2173 - accuracy: 0.9123 - 330ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "208/208 - 0s - loss: 0.2178 - accuracy: 0.9124 - 328ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "208/208 - 0s - loss: 0.2174 - accuracy: 0.9123 - 334ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "208/208 - 0s - loss: 0.2183 - accuracy: 0.9117 - 334ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "208/208 - 0s - loss: 0.2183 - accuracy: 0.9112 - 296ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "208/208 - 0s - loss: 0.2171 - accuracy: 0.9106 - 300ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "208/208 - 0s - loss: 0.2169 - accuracy: 0.9120 - 317ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "208/208 - 0s - loss: 0.2173 - accuracy: 0.9112 - 304ms/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "208/208 - 0s - loss: 0.2174 - accuracy: 0.9110 - 317ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "208/208 - 0s - loss: 0.2194 - accuracy: 0.9122 - 303ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "208/208 - 0s - loss: 0.2175 - accuracy: 0.9130 - 312ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "208/208 - 0s - loss: 0.2177 - accuracy: 0.9120 - 300ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "208/208 - 0s - loss: 0.2184 - accuracy: 0.9107 - 300ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "208/208 - 0s - loss: 0.2162 - accuracy: 0.9111 - 301ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "208/208 - 0s - loss: 0.2156 - accuracy: 0.9110 - 299ms/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "208/208 - 0s - loss: 0.2178 - accuracy: 0.9119 - 316ms/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "208/208 - 0s - loss: 0.2163 - accuracy: 0.9124 - 298ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "208/208 - 0s - loss: 0.2163 - accuracy: 0.9131 - 302ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "208/208 - 0s - loss: 0.2172 - accuracy: 0.9111 - 315ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "208/208 - 0s - loss: 0.2162 - accuracy: 0.9130 - 317ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "208/208 - 0s - loss: 0.2170 - accuracy: 0.9119 - 300ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "208/208 - 0s - loss: 0.2163 - accuracy: 0.9138 - 283ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "208/208 - 0s - loss: 0.2174 - accuracy: 0.9117 - 299ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "208/208 - 0s - loss: 0.2173 - accuracy: 0.9116 - 307ms/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "208/208 - 0s - loss: 0.2166 - accuracy: 0.9127 - 300ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "208/208 - 0s - loss: 0.2172 - accuracy: 0.9119 - 317ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "208/208 - 0s - loss: 0.2159 - accuracy: 0.9138 - 300ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "208/208 - 0s - loss: 0.2150 - accuracy: 0.9120 - 321ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "208/208 - 0s - loss: 0.2172 - accuracy: 0.9121 - 312ms/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "208/208 - 0s - loss: 0.2161 - accuracy: 0.9121 - 318ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "208/208 - 0s - loss: 0.2143 - accuracy: 0.9136 - 296ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "208/208 - 0s - loss: 0.2158 - accuracy: 0.9127 - 317ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "208/208 - 0s - loss: 0.2166 - accuracy: 0.9130 - 300ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "208/208 - 0s - loss: 0.2164 - accuracy: 0.9122 - 316ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "208/208 - 0s - loss: 0.2161 - accuracy: 0.9109 - 329ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "208/208 - 0s - loss: 0.2158 - accuracy: 0.9128 - 339ms/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "208/208 - 0s - loss: 0.2157 - accuracy: 0.9128 - 330ms/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "208/208 - 0s - loss: 0.2159 - accuracy: 0.9103 - 317ms/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "208/208 - 0s - loss: 0.2157 - accuracy: 0.9119 - 317ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "208/208 - 0s - loss: 0.2145 - accuracy: 0.9128 - 316ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "208/208 - 0s - loss: 0.2164 - accuracy: 0.9121 - 316ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "208/208 - 0s - loss: 0.2147 - accuracy: 0.9121 - 317ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "208/208 - 0s - loss: 0.2169 - accuracy: 0.9127 - 316ms/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "208/208 - 0s - loss: 0.2170 - accuracy: 0.9105 - 333ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "208/208 - 0s - loss: 0.2151 - accuracy: 0.9131 - 338ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "208/208 - 0s - loss: 0.2151 - accuracy: 0.9118 - 360ms/epoch - 2ms/step\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9192\n",
      "loss, acc: [0.20367632806301117, 0.9191918969154358]\n",
      "Epoch 1/50\n",
      "68/68 - 0s - loss: 0.6713 - accuracy: 0.7869 - 111ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "68/68 - 0s - loss: 0.3401 - accuracy: 0.8170 - 111ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "68/68 - 0s - loss: 0.3388 - accuracy: 0.8215 - 118ms/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "68/68 - 0s - loss: 0.3374 - accuracy: 0.8185 - 114ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "68/68 - 0s - loss: 0.3360 - accuracy: 0.8212 - 117ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "68/68 - 0s - loss: 0.3340 - accuracy: 0.8259 - 101ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "68/68 - 0s - loss: 0.3323 - accuracy: 0.8253 - 119ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "68/68 - 0s - loss: 0.3335 - accuracy: 0.8256 - 100ms/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "68/68 - 0s - loss: 0.3319 - accuracy: 0.8235 - 95ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "68/68 - 0s - loss: 0.3340 - accuracy: 0.8265 - 101ms/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "68/68 - 0s - loss: 0.3309 - accuracy: 0.8271 - 99ms/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "68/68 - 0s - loss: 0.3331 - accuracy: 0.8256 - 118ms/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "68/68 - 0s - loss: 0.3300 - accuracy: 0.8271 - 99ms/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "68/68 - 0s - loss: 0.3318 - accuracy: 0.8274 - 100ms/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "68/68 - 0s - loss: 0.3314 - accuracy: 0.8247 - 103ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "68/68 - 0s - loss: 0.3298 - accuracy: 0.8289 - 102ms/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "68/68 - 0s - loss: 0.3309 - accuracy: 0.8265 - 95ms/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "68/68 - 0s - loss: 0.3314 - accuracy: 0.8253 - 95ms/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "68/68 - 0s - loss: 0.3301 - accuracy: 0.8262 - 102ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "68/68 - 0s - loss: 0.3287 - accuracy: 0.8268 - 101ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "68/68 - 0s - loss: 0.3296 - accuracy: 0.8289 - 101ms/epoch - 1ms/step\n",
      "Epoch 22/50\n",
      "68/68 - 0s - loss: 0.3295 - accuracy: 0.8295 - 101ms/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "68/68 - 0s - loss: 0.3343 - accuracy: 0.8191 - 96ms/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "68/68 - 0s - loss: 0.3288 - accuracy: 0.8274 - 104ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "68/68 - 0s - loss: 0.3304 - accuracy: 0.8274 - 99ms/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "68/68 - 0s - loss: 0.3284 - accuracy: 0.8271 - 116ms/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "68/68 - 0s - loss: 0.3280 - accuracy: 0.8262 - 100ms/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "68/68 - 0s - loss: 0.3310 - accuracy: 0.8256 - 116ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "68/68 - 0s - loss: 0.3298 - accuracy: 0.8268 - 101ms/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "68/68 - 0s - loss: 0.3303 - accuracy: 0.8218 - 115ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "68/68 - 0s - loss: 0.3270 - accuracy: 0.8289 - 102ms/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "68/68 - 0s - loss: 0.3292 - accuracy: 0.8271 - 137ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "68/68 - 0s - loss: 0.3285 - accuracy: 0.8277 - 83ms/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "68/68 - 0s - loss: 0.3293 - accuracy: 0.8286 - 101ms/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "68/68 - 0s - loss: 0.3280 - accuracy: 0.8265 - 100ms/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "68/68 - 0s - loss: 0.3275 - accuracy: 0.8304 - 114ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "68/68 - 0s - loss: 0.3285 - accuracy: 0.8238 - 104ms/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "68/68 - 0s - loss: 0.3284 - accuracy: 0.8283 - 100ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "68/68 - 0s - loss: 0.3252 - accuracy: 0.8298 - 105ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "68/68 - 0s - loss: 0.3267 - accuracy: 0.8277 - 100ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "68/68 - 0s - loss: 0.3260 - accuracy: 0.8241 - 115ms/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "68/68 - 0s - loss: 0.3282 - accuracy: 0.8256 - 116ms/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "68/68 - 0s - loss: 0.3286 - accuracy: 0.8256 - 102ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "68/68 - 0s - loss: 0.3269 - accuracy: 0.8283 - 101ms/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "68/68 - 0s - loss: 0.3268 - accuracy: 0.8244 - 109ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "68/68 - 0s - loss: 0.3291 - accuracy: 0.8209 - 103ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "68/68 - 0s - loss: 0.3265 - accuracy: 0.8256 - 102ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "68/68 - 0s - loss: 0.3249 - accuracy: 0.8295 - 102ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "68/68 - 0s - loss: 0.3260 - accuracy: 0.8295 - 99ms/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "68/68 - 0s - loss: 0.3262 - accuracy: 0.8244 - 115ms/epoch - 2ms/step\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.7864\n",
      "loss, acc: [0.36916932463645935, 0.7864164710044861]\n",
      "Epoch 1/50\n",
      "356/356 - 1s - loss: 0.3280 - accuracy: 0.8208 - 546ms/epoch - 2ms/step\n",
      "Epoch 2/50\n",
      "356/356 - 1s - loss: 0.3220 - accuracy: 0.8213 - 534ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "356/356 - 1s - loss: 0.3217 - accuracy: 0.8236 - 532ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "356/356 - 1s - loss: 0.3203 - accuracy: 0.8207 - 566ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "356/356 - 1s - loss: 0.3183 - accuracy: 0.8225 - 535ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "356/356 - 1s - loss: 0.3184 - accuracy: 0.8210 - 554ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "356/356 - 1s - loss: 0.3190 - accuracy: 0.8225 - 546ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "356/356 - 1s - loss: 0.3187 - accuracy: 0.8216 - 537ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "356/356 - 1s - loss: 0.3176 - accuracy: 0.8241 - 530ms/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "356/356 - 1s - loss: 0.3167 - accuracy: 0.8236 - 537ms/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "356/356 - 1s - loss: 0.3171 - accuracy: 0.8237 - 543ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "356/356 - 1s - loss: 0.3176 - accuracy: 0.8259 - 571ms/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "356/356 - 1s - loss: 0.3164 - accuracy: 0.8255 - 553ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "356/356 - 1s - loss: 0.3169 - accuracy: 0.8234 - 560ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "356/356 - 1s - loss: 0.3149 - accuracy: 0.8248 - 554ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "356/356 - 1s - loss: 0.3160 - accuracy: 0.8226 - 547ms/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "356/356 - 1s - loss: 0.3156 - accuracy: 0.8262 - 549ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "356/356 - 1s - loss: 0.3146 - accuracy: 0.8262 - 564ms/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "356/356 - 1s - loss: 0.3156 - accuracy: 0.8263 - 539ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "356/356 - 1s - loss: 0.3153 - accuracy: 0.8258 - 526ms/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "356/356 - 1s - loss: 0.3161 - accuracy: 0.8237 - 555ms/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "356/356 - 1s - loss: 0.3140 - accuracy: 0.8267 - 543ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "356/356 - 1s - loss: 0.3156 - accuracy: 0.8240 - 565ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "356/356 - 1s - loss: 0.3142 - accuracy: 0.8257 - 555ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "356/356 - 1s - loss: 0.3139 - accuracy: 0.8257 - 546ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "356/356 - 1s - loss: 0.3146 - accuracy: 0.8244 - 533ms/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "356/356 - 1s - loss: 0.3139 - accuracy: 0.8258 - 567ms/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "356/356 - 1s - loss: 0.3144 - accuracy: 0.8259 - 566ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "356/356 - 1s - loss: 0.3142 - accuracy: 0.8253 - 582ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "356/356 - 1s - loss: 0.3137 - accuracy: 0.8249 - 515ms/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "356/356 - 1s - loss: 0.3140 - accuracy: 0.8248 - 547ms/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "356/356 - 1s - loss: 0.3133 - accuracy: 0.8259 - 557ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "356/356 - 1s - loss: 0.3131 - accuracy: 0.8275 - 564ms/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "356/356 - 1s - loss: 0.3134 - accuracy: 0.8252 - 584ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "356/356 - 1s - loss: 0.3140 - accuracy: 0.8264 - 548ms/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "356/356 - 1s - loss: 0.3128 - accuracy: 0.8277 - 548ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "356/356 - 1s - loss: 0.3133 - accuracy: 0.8246 - 533ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "356/356 - 1s - loss: 0.3126 - accuracy: 0.8273 - 520ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "356/356 - 1s - loss: 0.3141 - accuracy: 0.8250 - 501ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "356/356 - 1s - loss: 0.3128 - accuracy: 0.8257 - 553ms/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "356/356 - 1s - loss: 0.3120 - accuracy: 0.8278 - 570ms/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "356/356 - 1s - loss: 0.3122 - accuracy: 0.8264 - 532ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "356/356 - 1s - loss: 0.3116 - accuracy: 0.8271 - 545ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "356/356 - 1s - loss: 0.3119 - accuracy: 0.8258 - 556ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "356/356 - 1s - loss: 0.3120 - accuracy: 0.8276 - 566ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "356/356 - 1s - loss: 0.3119 - accuracy: 0.8266 - 584ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "356/356 - 1s - loss: 0.3114 - accuracy: 0.8290 - 532ms/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "356/356 - 1s - loss: 0.3122 - accuracy: 0.8249 - 565ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "356/356 - 1s - loss: 0.3119 - accuracy: 0.8266 - 549ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "356/356 - 1s - loss: 0.3122 - accuracy: 0.8281 - 535ms/epoch - 2ms/step\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8280\n",
      "loss, acc: [0.3197845220565796, 0.8279878497123718]\n"
     ]
    }
   ],
   "source": [
    "fitting(x_Scaled_Dis_train,\n",
    "        x_Scaled_Dis_test,\n",
    "        y_UnderSampled_Dis_train,\n",
    "        y_UnderSampled_Dis_test, None, None)\n",
    "fitting(x_Scaled_US_train,\n",
    "        x_Scaled_US_test,\n",
    "        y_UnderSampled_US_train,\n",
    "        y_UnderSampled_US_test, None, None)\n",
    "fitting(x_Scaled_OS_train,\n",
    "        x_Scaled_OS_test,\n",
    "        y_UnderSampled_OS_train,\n",
    "        y_UnderSampled_OS_test, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wrap the best performing model for deployment using tabpy\n",
    "from keras_pickle_wrapper import KerasPickleWrapper\n",
    "import pickle\n",
    "import keras \n",
    "best_fit = KerasPickleWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup tapby for Tableau connection\n",
    "from tabpy.tabpy_tools.client import Client\n",
    "from tabpy import tabpy_tools\n",
    "\n",
    "client = Client('http://localhost:9004/')\n",
    "client.set_credentials('Yourname', 'PassHere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write a passable function to wrap the model in \n",
    "## This code has been adopted from a very handy tabpy tutorial!\n",
    "# https://medium.com/geekculture/deep-learning-in-tableau-using-a-keras-neural-network-and-python-tabpy-8f8716c35488\n",
    "def PredictedConversion(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8, _arg9, _arg10):\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    \n",
    "    row = {'Book Length Overall': _arg1,\n",
    "           'Book Length Average': _arg2,\n",
    "           'Price Overall': _arg3,\n",
    "           'Price Average': _arg4,\n",
    "           \n",
    "           'Review': _arg5,\n",
    "           'Review10/10': _arg6,\n",
    "           'Minutes Listened': _arg7,\n",
    "           'Completion': _arg8,\n",
    "           'Support Requests': _arg9,\n",
    "           \n",
    "           'Last Visited Minus Purchase Date': _arg10,\n",
    "\n",
    "           }\n",
    "\n",
    "    \n",
    "    X = pd.DataFrame(data = row, index=[0])\n",
    "    return str(best_fit().predict(X)[0][0])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpypy9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
